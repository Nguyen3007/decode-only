Dá»± Ã¡n nÃ y thá»±c hiá»‡n Supervised Fine-Tuning (SFT) mÃ´ hÃ¬nh Qwen/Qwen2.5-1.5B-Instruct theo dáº¡ng decoder-only causal language modeling trÃªn táº­p dá»¯ liá»‡u ViHealthQA (Vietnamese Health Q&A).

Project Ä‘Æ°á»£c thiáº¿t káº¿ tá»‘i giáº£n, dá»… huáº¥n luyá»‡n trÃªn GPU (Vast.ai, Colab Pro, Kaggle), vá»›i kiáº¿n trÃºc rÃµ rÃ ng vÃ  dá»… má»Ÿ rá»™ng.

ğŸ“ Project Structure
decode-only/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py        # Cáº¥u hÃ¬nh training + Ä‘Æ°á»ng dáº«n
â”‚   â”œâ”€â”€ data.py          # Load vÃ  kiá»ƒm tra dataset ViHealthQA
â”‚   â”œâ”€â”€ trainer.py       # Fine-tune Qwen2.5-1.5B theo kiá»ƒu causal LM
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ requirements.txt     # CÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
â””â”€â”€ README.md

ğŸ“¦ Dataset: ViHealthQA

Dataset sá»­ dá»¥ng:
tarudesu/ViHealthQA
(Ná»™i dung: cÃ¢u há»i â€“ tráº£ lá»i y táº¿ tiáº¿ng Viá»‡t, 3 split: train / validation / test)

VÃ­ dá»¥ 1 máº«u:

{
  "id": 1,
  "question": "Äang chÃ­ch ngá»«a viÃªm gan B cÃ³ chÃ­ch ngá»«a Covid-19 Ä‘Æ°á»£c khÃ´ng?",
  "answer": "Náº¿u anh/chá»‹ Ä‘ang tiÃªm ngá»«a vaccine phÃ²ng bá»‡nh viÃªm gan B... ",
  "link": "https://vnexpress.net/..."
}

ğŸš€ 1. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

Trong mÃ´i trÆ°á»ng Python 3.10+:

pip install -r requirements.txt

ğŸ” 2. Kiá»ƒm tra dataset

Báº¡n cÃ³ thá»ƒ cháº¡y thá»­ viá»‡c load dataset:

python -m src.data


Output sáº½ hiá»ƒn thá»‹ tá»•ng sá»‘ máº«u vÃ  1 sample Ä‘á»ƒ kiá»ƒm tra.

ğŸ‹ï¸ 3. Fine-tune mÃ´ hÃ¬nh (SFT Decoder-Only)

Huáº¥n luyá»‡n mÃ´ hÃ¬nh Qwen2.5-1.5B trÃªn ViHealthQA:

python -m src.trainer


trainer.py sáº½ tá»± Ä‘á»™ng:

Load dataset

Load tokenizer + model

XÃ¢y dá»±ng chat template cho dáº¡ng Q&A

Tokenize & sinh labels (causal LM)

Huáº¥n luyá»‡n vá»›i Trainer()

LÆ°u checkpoint vÃ o:

checkpoints/qwen2_5_1_5b_vihealthqa/

ğŸ§© 4. Cáº¥u hÃ¬nh training

Má»i hyperparameter náº±m trong src/config.py.

VÃ­ dá»¥:

model_name = "Qwen/Qwen2.5-1.5B-Instruct"
max_seq_length = 1024
batch_size = 2
gradient_accumulation_steps = 8
num_train_epochs = 3
learning_rate = 1e-5


Báº¡n cÃ³ thá»ƒ chá»‰nh á»Ÿ Ä‘Ã¢y thay vÃ¬ sá»­a nhiá»u file.

ğŸ§ª 5. Evaluate (sáº½ thÃªm sau)

Dá»± Ã¡n sáº½ sá»›m bá»• sung file evaluate.py Ä‘á»ƒ:

Generate cÃ¢u tráº£ lá»i tá»« checkpoint Ä‘Ã£ fine-tune

So sÃ¡nh vá»›i ground truth

TÃ­nh ROUGE / BLEU

ğŸ”§ 6. Huáº¥n luyá»‡n trÃªn GPU (Vast.ai)

Khi clone repo trÃªn Vast.ai:

git clone https://github.com/Nguyen3007/decode-only.git
cd decode-only
pip install -r requirements.txt
python -m src.trainer


GPU 12GB trá»Ÿ lÃªn Ä‘Æ°á»£c khuyáº¿n nghá»‹ cho Qwen 1.5B.

ğŸ“Œ Ghi chÃº

Local CPU cÃ³ thá»ƒ cháº¡y tokenization, nhÆ°ng khÃ´ng phÃ¹ há»£p Ä‘á»ƒ train Qwen2.5-1.5B.

Khi train trÃªn GPU 12GB, nÃªn giáº£m:

max_seq_length = 512

per_device_train_batch_size = 1

gradient_accumulation_steps = 16

âœ¨ Má»¥c tiÃªu dá»± Ã¡n

XÃ¢y dá»±ng pipeline SFT decoder-only rÃµ rÃ ng vÃ  dá»… tÃ¡i sá»­ dá»¥ng cho mÃ´ hÃ¬nh LLM.

Fine-tune chuyÃªn sÃ¢u mÃ´ hÃ¬nh Qwen trÃªn nhiá»‡m vá»¥ Q&A y táº¿ tiáº¿ng Viá»‡t.

Chuáº©n bá»‹ Ä‘á»ƒ má»Ÿ rá»™ng sang:

LoRA / QLoRA

RAG

Evaluate nÃ¢ng cao

Deployment (FastAPI, HF Spaces)

ğŸ‘¤ TÃ¡c giáº£

Nguyen3007
Sinh viÃªn ngÃ nh Khoa há»c mÃ¡y tÃ­nh â€” yÃªu thÃ­ch NLP, LLM, Recommender Systems.
