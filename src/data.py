# src/data.py
from typing import Optional

from datasets import DatasetDict, load_dataset

from .config import train_config, paths


# src/data.py
from typing import Optional

from datasets import DatasetDict, load_dataset

from .config import train_config, paths


def load_vihealthqa(
    cache_dir: Optional[str] = None,
) -> DatasetDict:
    """
    Load full ViHealthQA tá»« HuggingFace Datasets.

    Dataset cÃ³ 3 split: train / validation / test
    vá»›i cÃ¡c cá»™t chÃ­nh: id, question, answer, link.
    """
    paths.make_dirs()

    print(f"ðŸ”¹ Loading dataset: {train_config.dataset_name}")
    ds = load_dataset(
        train_config.dataset_name,
        cache_dir=cache_dir,
        # KHÃ”NG cÃ²n dÃ¹ng trust_remote_code á»Ÿ Ä‘Ã¢y
    )

    print(ds)
    print("\nðŸ“Œ Sample train row:")
    print(ds["train"][0])

    return ds



def main() -> None:
    """
    Cho phÃ©p cháº¡y file nÃ y trá»±c tiáº¿p:
    python -m src.data
    Ä‘á»ƒ test viá»‡c load dataset.
    """
    ds = load_vihealthqa()
    print("\nâœ… Loaded ViHealthQA successfully!")
    print("Splits:", ds.keys())
    for split in ds.keys():
        print(f"{split}: {len(ds[split])} examples")


if __name__ == "__main__":
    main()
